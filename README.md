<p align="center">
  <h1 align="center"> Enterprise AI Agent Engine</h1>
  <p align="center">
    <strong>Production-ready, modular AI agent backend with planning, tool routing, RAG, memory, caching, guardrails, and observability.</strong>
  </p>
  <p align="center">
    <img src="https://img.shields.io/badge/Python-3.11-blue?logo=python&logoColor=white" alt="Python" />
    <img src="https://img.shields.io/badge/FastAPI-0.110+-green?logo=fastapi&logoColor=white" alt="FastAPI" />
    <img src="https://img.shields.io/badge/Ollama-LLaMA3-orange?logo=meta&logoColor=white" alt="Ollama" />
    <img src="https://img.shields.io/badge/MongoDB-6.0-47A248?logo=mongodb&logoColor=white" alt="MongoDB" />
    <img src="https://img.shields.io/badge/Redis-7.0-DC382D?logo=redis&logoColor=white" alt="Redis" />
    <img src="https://img.shields.io/badge/Celery-5.x-37814A?logo=celery&logoColor=white" alt="Celery" />
    <img src="https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white" alt="Docker" />
  </p>
</p>

---

## ğŸ“– Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
- [Running the Application](#running-the-application)
  - [Enterprise Local Runbook](#-enterprise-local-runbook)
- [API Reference](#api-reference)
- [How It Works](#how-it-works)
- [Use Cases](#use-cases)
- [Deployment](#deployment)
- [License](#license)

---

## Overview

The **Enterprise AI Agent Engine** is a production-grade, modular AI backend system that goes far beyond a simple chatbot. It accepts a user goal, generates an intelligent multi-step execution plan using a local LLM (Ollama + LLaMA3), routes each step to the appropriate tool (RAG search, web search, etc.), executes them with enterprise reliability patterns, and synthesizes a final response â€” all with full observability, caching, memory, and security guardrails.

This project demonstrates real-world AI system engineering: the kind of architecture used internally at companies building AI-powered products at scale.

---

## Key Features

| Category | Feature |
|---|---|
| ğŸ¤– **AI Planning** | LLM-powered multi-step plan generation with auto-repair for malformed JSON |
| ğŸ”€ **Intelligent Routing** | Semantic similarity-based tool selection with configurable thresholds |
| ğŸ” **RAG Pipeline** | Retrieval-Augmented Generation with local embeddings and vector search |
| ğŸŒ **Web Search** | Integrated web search tool for real-time information retrieval |
| ğŸ’¾ **Response Caching** | Smart cache layer (MongoDB-backed) to avoid redundant LLM calls |
| ğŸ§  **Memory System** | Session-aware short-term + semantic long-term memory for context continuity |
| ğŸ›¡ï¸ **Security Guardrails** | Input validation, prompt injection detection, tool whitelist enforcement, output sanitization |
| âš¡ **Reliability** | Retry policies, timeout executors, concurrent tool execution with semaphores |
| ğŸ“Š **Observability** | Structured logging, Prometheus metrics, full execution traces stored in MongoDB |
| ğŸ”‘ **API Key Auth** | Header-based API key authentication on protected endpoints |
| ğŸ³ **Docker Ready** | Multi-stage Dockerfile with Gunicorn + Uvicorn workers |
| ğŸ“¦ **Async Workers** | Celery + Redis for background task processing |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Client (curl / Postman / Frontend)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  HTTP (JSON)
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI  (api/app.py)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ /health  â”‚  â”‚ /metrics  â”‚  â”‚ /agent/run   â”‚  â”‚ /traces/{id} â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚                             â”‚
â”‚           API Key Auth  Â·  Input Validation  Â·  Rate Limiting      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PlanningAgentService  (app/services/)                  â”‚
â”‚                                                                     â”‚
â”‚   1. Guardrails â†’ validate input                                    â”‚
â”‚   2. LLM (Ollama) â†’ generate execution plan (JSON)                 â”‚
â”‚   3. Parse + auto-repair plan                                       â”‚
â”‚   4. Guardrails â†’ validate plan (tool whitelist, step limits)       â”‚
â”‚   5. Cache check â†’ return cached response if hit                    â”‚
â”‚   6. IntelligentRouter â†’ execute each step via tools                â”‚
â”‚   7. Guardrails â†’ sanitize tool outputs                             â”‚
â”‚   8. Memory â†’ retrieve session context                              â”‚
â”‚   9. LLM (Ollama) â†’ synthesize final answer                        â”‚
â”‚  10. Guardrails â†’ validate final answer                             â”‚
â”‚  11. Cache + Memory â†’ persist results                               â”‚
â”‚  12. Trace â†’ store full execution trace in MongoDB                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                   â”‚
          â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tool Registry   â”‚              â”‚   Memory Manager   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ RAG Search â”‚  â”‚              â”‚  â”‚  Short-term  â”‚  â”‚
â”‚  â”‚ Web Search â”‚  â”‚              â”‚  â”‚  Long-term   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚  â”‚  (Semantic)  â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                   â”‚
          â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Redis (Broker) â”‚              â”‚  MongoDB (Storage)  â”‚
â”‚   Celery Worker  â”‚              â”‚  Traces Â· Cache     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  Memory Â· Vectors   â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tech Stack

| Layer | Technology |
|---|---|
| **Language** | Python 3.11 |
| **Web Framework** | FastAPI (ASGI) |
| **LLM Runtime** | Ollama (local) with LLaMA3 8B Instruct |
| **Embeddings** | Sentence-Transformers (local) |
| **Database** | MongoDB 6.0 |
| **Message Broker** | Redis 7.0 |
| **Task Queue** | Celery 5.x |
| **Containerization** | Docker (multi-stage build) |
| **ASGI Server** | Uvicorn (dev) / Gunicorn + Uvicorn (prod) |
| **Metrics** | Prometheus client |
| **Validation** | Pydantic v2 |

---

## Project Structure

```
genai-agent-sprint/
â”‚
â”œâ”€â”€ api/                          # API layer (FastAPI)
â”‚   â”œâ”€â”€ app.py                    # FastAPI entrypoint, middleware, routes
â”‚   â”œâ”€â”€ dependencies.py           # Agent assembly & dependency injection
â”‚   â””â”€â”€ schemas.py                # Pydantic request/response models
â”‚
â”œâ”€â”€ app/                          # Core application logic
â”‚   â”œâ”€â”€ services/                 # Business logic services
â”‚   â”‚   â”œâ”€â”€ planning_agent_service.py   # Main planning agent (plan â†’ execute â†’ synthesize)
â”‚   â”‚   â”œâ”€â”€ embedding_service.py        # Text embedding generation
â”‚   â”‚   â””â”€â”€ retriever_service.py        # Vector similarity retrieval
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                    # Agent tools
â”‚   â”‚   â”œâ”€â”€ rag_search_tool.py    # RAG-based document search
â”‚   â”‚   â””â”€â”€ web_search_tool.py    # Web search integration
â”‚   â”‚
â”‚   â”œâ”€â”€ routing/                  # Intelligent tool routing
â”‚   â”‚   â””â”€â”€ intelligent_router.py # Semantic similarity-based routing
â”‚   â”‚
â”‚   â”œâ”€â”€ registry/                 # Tool registration system
â”‚   â”‚   â””â”€â”€ tool_registry.py      # Central tool registry
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                   # Memory management
â”‚   â”‚   â”œâ”€â”€ memory_manager.py     # Short-term + long-term memory
â”‚   â”‚   â””â”€â”€ database.py           # MongoDB connection & indexes
â”‚   â”‚
â”‚   â”œâ”€â”€ cache/                    # Caching layer
â”‚   â”‚   â””â”€â”€ response_cache.py     # Smart response caching
â”‚   â”‚
â”‚   â”œâ”€â”€ security/                 # Security & guardrails
â”‚   â”‚   â””â”€â”€ guardrails.py         # Input/output validation, injection detection
â”‚   â”‚
â”‚   â”œâ”€â”€ infra/                    # Infrastructure utilities
â”‚   â”‚   â”œâ”€â”€ logger.py             # Structured logging + Prometheus metrics
â”‚   â”‚   â”œâ”€â”€ retry_policy.py       # Configurable retry with backoff
â”‚   â”‚   â”œâ”€â”€ timeout_executor.py   # Execution timeout enforcement
â”‚   â”‚   â”œâ”€â”€ reliable_executor.py  # Combined retry + timeout executor
â”‚   â”‚   â”œâ”€â”€ validators.py         # Input sanitization
â”‚   â”‚   â””â”€â”€ celery_app.py         # Celery application config
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                     # Core components
â”‚   â”‚   â””â”€â”€ vector_store.py       # Vector store for embeddings
â”‚   â”‚
â”‚   â”œâ”€â”€ observability/            # Monitoring & tracing
â”‚   â””â”€â”€ reliability/              # Reliability patterns
â”‚
â”œâ”€â”€ data/                         # Data files
â”‚   â””â”€â”€ sample.txt                # Sample document for RAG
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”œâ”€â”€ Dockerfile                    # Multi-stage production Docker build
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .env                          # Environment variables
â””â”€â”€ .gitignore
```

---

## Getting Started

### Prerequisites

| Requirement | Purpose |
|---|---|
| **Python 3.11+** | Runtime |
| **WSL 2 (Ubuntu)** | Linux environment on Windows |
| **Docker Desktop** | Running MongoDB & Redis containers |
| **Ollama** | Local LLM inference server |

### Installation

**1. Clone the repository**

```bash
git clone <your-repo-url>
cd genai-agent-sprint
```

**2. Create and activate virtual environment (WSL)**

```bash
python3 -m venv .venv
source .venv/bin/activate
```

**3. Install dependencies**

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**4. Pull the LLM model**

```bash
ollama pull llama3:8b-instruct-q4_K_M
```

**5. Configure environment**

Create a `.env` file in the project root (or edit the existing one):

```env
MONGO_URI=mongodb://localhost:27017
MONGO_DB_NAME=agent_db
REDIS_URL=redis://localhost:6379/0
API_KEY=supersecretkey
```

---

## Running the Application

### ğŸš€ Enterprise Local Runbook

Your backend consists of **separate processes** that mirror production architecture:

| Process | Role | Terminal |
|---|---|---|
| **MongoDB** | Database (traces, cache, memory) | Docker |
| **Redis** | Message broker for Celery | Docker |
| **FastAPI** | HTTP API server | Terminal 1 |
| **Celery Worker** | Async task processing | Terminal 2 |

---

#### Step 1 â€” Start Infrastructure (Docker)

Open **WSL terminal** and start MongoDB & Redis (one-time after reboot):

```bash
# Check if already running
docker ps

# Start if not running
docker run -d --name mongo -p 27017:27017 mongo:6
docker run -d --name redis -p 6379:6379 redis:7
```

**âœ… Verify:** `docker ps` should show both `mongo` and `redis` containers.

---

#### Step 2 â€” Start FastAPI Server (Terminal 1)

Open a **new WSL terminal**:

```bash
cd "/mnt/d/GenAI and AgenticAI/genai-agent-sprint"
source .venv/bin/activate

uvicorn api.app:app \
  --host 0.0.0.0 \
  --port 8000 \
  --reload
```

**âœ… Expected output:**

```
âœ… MongoDB connected and indexes ensured.
Application startup complete
Uvicorn running on http://0.0.0.0:8000
```

> âš ï¸ Keep this terminal running.

---

#### Step 3 â€” Start Celery Worker (Terminal 2)

Open **another WSL terminal**:

```bash
cd "/mnt/d/GenAI and AgenticAI/genai-agent-sprint"
source .venv/bin/activate

python -m celery \
  -A app.infra.celery_app worker \
  --loglevel=info \
  --concurrency=2
```

**âœ… Expected output:**

```
Connected to redis://localhost:6379/0
celery@... ready.
```

> âš ï¸ Keep this terminal running. Celery is **required** for full agent functionality.

---

#### Step 4 â€” Verify System Health

```bash
curl http://127.0.0.1:8000/health
```

**âœ… Expected:**

```json
{"status": "ok"}
```

---

#### Step 5 â€” Test the Agent

```bash
curl -X POST http://127.0.0.1:8000/agent/run \
  -H "Content-Type: application/json" \
  -H "x-api-key: supersecretkey" \
  -d '{"session_id":"test-user","goal":"Explain RAG simply"}'
```

---

### Quick Reference (Copy-Paste)

```bash
# === TERMINAL 0: Infrastructure ===
docker start mongo redis    # if containers exist but stopped

# === TERMINAL 1: FastAPI ===
cd "/mnt/d/GenAI and AgenticAI/genai-agent-sprint"
source .venv/bin/activate
uvicorn api.app:app --host 0.0.0.0 --port 8000 --reload

# === TERMINAL 2: Celery Worker ===
cd "/mnt/d/GenAI and AgenticAI/genai-agent-sprint"
source .venv/bin/activate
python -m celery -A app.infra.celery_app worker --loglevel=info --concurrency=2
```

---

## API Reference

### `GET /health`

Health check endpoint (no auth required).

```json
{"status": "ok"}
```

### `GET /ready`

Database readiness probe.

```json
{"status": "ready"}
```

### `GET /metrics`

Prometheus-compatible metrics endpoint.

### `POST /agent/run`

Execute an AI agent task.

**Headers:**

| Header | Value |
|---|---|
| `Content-Type` | `application/json` |
| `x-api-key` | Your API key |

**Request Body:**

```json
{
  "session_id": "unique-session-id",
  "goal": "Your question or task for the AI agent"
}
```

**Response:**

```json
{
  "result": "The agent's synthesized response",
  "request_id": "uuid-trace-id"
}
```

### `GET /traces/{request_id}`

Retrieve full execution trace for debugging (auth required).

---

## How It Works

```
User Goal â†’ Input Guardrails â†’ LLM Plan Generation â†’ Plan Validation
    â†’ Cache Check (hit? return cached) â†’ Tool Execution (parallel)
    â†’ Output Sanitization â†’ Memory Retrieval â†’ LLM Synthesis
    â†’ Final Answer Guardrails â†’ Cache + Memory Store â†’ Response
```

1. **Input Validation** â€” The user's goal is checked for prompt injection and sanitized.
2. **Plan Generation** â€” The LLM creates a structured JSON plan with tool calls.
3. **Plan Validation** â€” Guardrails enforce tool whitelists and step limits.
4. **Cache Lookup** â€” If an identical request was previously processed, the cached result is returned instantly.
5. **Parallel Tool Execution** â€” Steps are executed concurrently (up to 4 at a time) via the intelligent router.
6. **Output Sanitization** â€” Each tool's output is scanned for sensitive data leakage.
7. **Context Retrieval** â€” Session memory and semantically relevant past interactions are fetched.
8. **Answer Synthesis** â€” The LLM combines observations + memory into a final response.
9. **Post-Validation** â€” The final answer is checked for data leakage before being returned.
10. **Persistence** â€” Results are cached, memory is updated, and a full trace is stored.

---

## Use Cases

- **Enterprise Knowledge Assistant** â€” Query internal documents with RAG-powered search
- **Research Agent** â€” Combine web search + document retrieval for comprehensive answers
- **Customer Support Backend** â€” Session-aware, context-rich AI responses
- **AI Workflow Automation** â€” Multi-step task planning and execution
- **Interview Portfolio Project** â€” Demonstrates production AI system design skills

---

## Deployment

### Docker (Production)

```bash
docker build -t ai-agent-engine .
docker run -p 8000:8000 \
  -e MONGO_URI=mongodb://mongo:27017 \
  -e REDIS_URL=redis://redis:6379/0 \
  -e API_KEY=your-production-key \
  ai-agent-engine
```

The Dockerfile uses a **multi-stage build** with Gunicorn + Uvicorn workers for production performance.

### Production Architecture

```
nginx (reverse proxy)
  â””â”€â”€ Gunicorn + Uvicorn workers (FastAPI)
  â””â”€â”€ Celery worker pool
  â””â”€â”€ MongoDB (database)
  â””â”€â”€ Redis (broker)
  â””â”€â”€ Ollama (LLM server)
```

---

## Enterprise Design Highlights

| Concern | Implementation |
|---|---|
| **Separation of concerns** | API layer / services / tools / infra cleanly separated |
| **Dependency injection** | `build_agent()` wires all components at startup |
| **Reliability** | Retry with exponential backoff + timeout enforcement |
| **Security** | API key auth, input sanitization, prompt injection detection, output scanning |
| **Observability** | Structured logs, Prometheus metrics, full execution traces |
| **Performance** | Response caching, parallel tool execution, async I/O |
| **Memory** | Hybrid short-term (recent) + long-term (semantic) memory |
| **Scalability** | Celery workers, Docker-ready, stateless API design |

---

## License

This project is for educational and portfolio purposes.

---

<p align="center">
  <sub>Built with â¤ï¸ as part of the GenAI & Agentic AI System Builder Sprint</sub>
</p>
